{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST classification\n",
    "### Example adopted from Chapter 3 of _the fundamentals of Machine Learning and Deep Learning in Python using Scikit-Learn, Keras and TensorFlow 2_ [Text (early release)](https://icenamor.github.io/files/books/Hands-on-Machine-Learning-with-Scikit-2E.pdf) [GitHub](https://github.com/ageron/handson-ml2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"MNIST-classification\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST\n",
    "\n",
    "MNIST is a dataset of 70,000 small images of digits handwritten digits. Each image has 28×28 pixels, thus totol of 784 features. Each feature is a grey level value from 0 - 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)  # load dataset from https://openml.org/ \n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "some_digit = X[0]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "plt.imshow(some_digit_image, cmap=mpl.cm.binary)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "#save_fig(\"some_digit_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the char type into int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(np.uint8)\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digit(data):\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = mpl.cm.binary,\n",
    "               interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRA\n",
    "def plot_digits(instances, images_per_row=10, **options):\n",
    "    size = 28\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    images = [instance.reshape(size,size) for instance in instances]\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    plt.imshow(image, cmap = mpl.cm.binary, **options)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "example_images = X[:100]\n",
    "plot_digits(example_images, images_per_row=10)\n",
    "save_fig(\"more_digits_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset is already split into a training set (the first 60,000 images) and a test set (the last 10,000 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classifier\n",
    "Implement a _5 detector_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a data set for binary classification: 5 or not 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = (y_train == 5)\n",
    "y_test_5 = (y_test == 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Perceptron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "p_clf = Perceptron(tol=1e-3, eta0=0.1, random_state=42)  \n",
    "p_clf.fit(X_train, y_train_5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparameters: tol - the stopping criterion; eta0 - the learning rate; max_iter - optional (default=1000), and more\n",
    "\n",
    "**Note**: some hyperparameters will have a different defaut value in future versions of Scikit-Learn, such as `max_iter` and `tol`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try predict the first two images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_clf.predict([X[0], X[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation and use accuracy scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(p_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try a very dumb classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "never_5_clf = Never5Classifier()\n",
    "cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Evaluation with precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(p_clf, X_train, y_train_5, cv=3, scoring=\"precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(p_clf, X_train, y_train_5, cv=3, scoring=\"recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_train_pred = cross_val_predict(p_clf, X_train, y_train_5, cv=3)\n",
    "confusion_matrix(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalute the model on the hold-out test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = p_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_5, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "print(\"Accuracy score: \", (accuracy_score(y_test_5, y_test_pred)))\n",
    "print(\"Precision score: \", (precision_score(y_test_5, y_test_pred)))\n",
    "print(\"Recall score: \", (recall_score(y_test_5, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#iris = load_iris()\n",
    "#X = iris.data[:, (2, 3)] # petal length, petal width\n",
    "#y = (iris.target == 0).astype(np.int) # Iris Setosa?\n",
    "\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "some_digit = X[0]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "plt.imshow(some_digit_image, cmap = mpl.cm.binary, interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y = y.astype(np.uint8)\n",
    "\n",
    "\n",
    "# putting the image files into variables for test set and training (which has already been set up automatically):\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "\n",
    "# TRAINING BINARY CLASSIFIER:\n",
    "y_train_5 = (y_train == 5)\n",
    "# 5 vs not-5: True for 5, False for all other digits.\n",
    "y_test_5 = (y_test == 5)\n",
    "\n",
    "\n",
    "# PICKING/TRAINING A CLASSIFIER (and training):\n",
    "# Stochastic Gradient Descent (SGD) classifier\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)\n",
    "\n",
    "sgd_clf.predict([some_digit])\n",
    "\n",
    "# -------------------------------------------\n",
    "# performance eval (cross-validation and accuracy):\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print('accuracy determined from cross validation: ' + str(cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")))\n",
    "print('precision determined from cross validation: ' + str(cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"precision\")))\n",
    "print('recall determined from cross validation: ' + str(cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"recall\")))\n",
    "\n",
    "# a BETTER way to eval than cross-validation: CONFUSION MATRIX:\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)\n",
    "confusion_matrix(y_train_5, y_train_pred)\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# Deciding on a Threshold value to determine how/where classes get divided up by examining the precision/recall Tradeoff:\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_train_5, y_train_pred)\n",
    "recall_score(y_train_5, y_train_pred)\n",
    "\n",
    "y_scores = sgd_clf.decision_function([some_digit])\n",
    "\n",
    "threshold = 8000\n",
    "y_some_digit_pred = (y_scores > threshold)\n",
    "y_some_digit_pred\n",
    "\n",
    "\n",
    "\n",
    "# get decision scores data to compute precision and recall for all possible thresholds-- \n",
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, method=\"decision_function\")\n",
    "\n",
    "# --by way of precision_recall_curve() function:\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)\n",
    "\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "\tplt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "\tplt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "\n",
    "\n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "\n",
    "threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)]\n",
    "y_train_pred_90 = (y_scores >= threshold_90_precision)\n",
    "\n",
    "print('precision score calculated using 90 percent precision classifier: ' + str(precision_score(y_train_5, y_train_pred_90)))\n",
    "print('recall score calculated using 90 percent precision classifier: ' + str(recall_score(y_train_5, y_train_pred_90)))\n",
    "\n",
    "#...We have now finished construction of a 90% precision classifier.\n",
    "\n",
    "# -------------------------------------------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is our work (most of it-- didnt have time to test since every re-test takes ten minutes minimum);\n",
    "import numpy as np\n",
    "\n",
    "# fetch dataset:\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "#mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist = fetch_openml('mnist_784', cache=True, version=1)\n",
    "mnist.keys()\n",
    "\n",
    "#iris = load_iris()\n",
    "#X = iris.data[:, (2, 3)] # petal length, petal width\n",
    "#y = (iris.target == 0).astype(np.int) # Iris Setosa?\n",
    "\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "some_digit = X[0]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "plt.imshow(some_digit_image, cmap = mpl.cm.binary, interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y = y.astype(np.uint8)\n",
    "\n",
    "\n",
    "# putting the image files into variables for test set and training (which has already been set up automatically):\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "\n",
    "# TRAINING BINARY CLASSIFIER:\n",
    "y_train_5 = (y_train == 5)\n",
    "# 5 vs not-5: True for 5, False for all other digits.\n",
    "y_test_5 = (y_test == 5)\n",
    "\n",
    "\n",
    "# PICKING/TRAINING A CLASSIFIER (and training):\n",
    "# Stochastic Gradient Descent (SGD) classifier\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)\n",
    "\n",
    "sgd_clf.predict([some_digit])\n",
    "\n",
    "# -------------------------------------------\n",
    "# performance eval (cross-validation and accuracy):\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print('accuracy determined from cross validation: ' + str(cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")))\n",
    "print('precision determined from cross validation: ' + str(cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"precision\")))\n",
    "print('recall determined from cross validation: ' + str(cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"recall\")))\n",
    "\n",
    "# a BETTER way to eval than cross-validation: CONFUSION MATRIX:\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)\n",
    "confusion_matrix(y_train_5, y_train_pred)\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# Deciding on a Threshold value to determine how/where classes get divided up by examining the precision/recall Tradeoff:\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_train_5, y_train_pred)\n",
    "recall_score(y_train_5, y_train_pred)\n",
    "\n",
    "y_scores = sgd_clf.decision_function([some_digit])\n",
    "\n",
    "threshold = 8000\n",
    "y_some_digit_pred = (y_scores > threshold)\n",
    "y_some_digit_pred\n",
    "\n",
    "\n",
    "\n",
    "# get decision scores data to compute precision and recall for all possible thresholds-- \n",
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, method=\"decision_function\")\n",
    "\n",
    "# --by way of precision_recall_curve() function:\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)\n",
    "\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "\tplt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "\tplt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "\n",
    "\n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "\n",
    "threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)]\n",
    "y_train_pred_90 = (y_scores >= threshold_90_precision)\n",
    "\n",
    "print('precision score calculated using 90 percent precision classifier: ' + str(precision_score(y_train_5, y_train_pred_90)))\n",
    "print('recall score calculated using 90 percent precision classifier: ' + str(recall_score(y_train_5, y_train_pred_90)))\n",
    "\n",
    "#...We have now finished construction of a 90% precision classifier.\n",
    "\n",
    "# -------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)\n",
    "print('Confusion Matrix for stochastic gradient descent: ' + str(confusion_matrix(y_train_5, y_train_pred)))\n",
    "\n",
    "c_matrix1 = confusion_matrix(y_train_5, y_train_pred)\n",
    "\n",
    "# TP FP\n",
    "# FN TN\n",
    "\n",
    "TP1 = c_matrix[0][0]\n",
    "FP1 = c_matrix[0][1]\n",
    "FN1 = c_matrix[1][0]\n",
    "TN1 = c_matrix[1][1]\n",
    "\n",
    "matrix_accuracy = (TP1+TN1) / (TP1+FP1+FN1+TN1)\n",
    "print('accuracy calculated from confusion matrix was: ' + str(matrix_accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Use a Stochastic Gradient Descent Classifier and evalute the model performance. Evalue the accuracy, precision and recall scores with cross validation. Print the confusion matrix. Try differnt hyperparameters and what is the best model you can get. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resulting output from previous tests was as follows:\n",
    "#accuracy determined from cross validation: [0.95035 0.96035 0.9604 ]\n",
    "#precision determined from cross validation: [0.95936795 0.89060092 0.74963109]\n",
    "#recall determined from cross validation: [0.47039292 0.63973437 0.84338683]\n",
    "#precision score calculated using 90 percent precision classifier: 0.9000345901072293\n",
    "#recall score calculated using 90 percent precision classifier: 0.4799852425751706\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Apply feature standardization to see if such feature transformation can improve the performance of the Stochastic Gradient Descent on the test data. Explain your findings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler() #center the distribution around zero (mean), with a standard deviation of 1.\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
